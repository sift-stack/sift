from __future__ import annotations

import asyncio
import logging
from datetime import datetime
from typing import Any, cast

import numpy as np

from sift.channels.v3.channels_pb2 import (
    GetChannelRequest,
    GetChannelResponse,
    ListChannelsRequest,
    ListChannelsResponse,
)
from sift.data.v2.data_pb2 import (
    ChannelQuery,
    GetDataRequest,
    GetDataResponse,
    Query,
    DoubleValues,
    FloatValues,
    StringValues,
    EnumValues,
    BoolValues,
    Int32Values,
    Int64Values,
    Uint32Values,
    Uint64Values,
    BitFieldValues,
    Metadata,
)
from sift.data.v2.data_pb2_grpc import DataServiceStub
from sift.channels.v3.channels_pb2_grpc import ChannelServiceStub

from sift_py._internal.time import to_timestamp_nanos

from sift_client._internal.low_level_wrappers.base import LowLevelClientBase
from sift_client.transport.grpc_transport import GrpcClient
from sift_client.types.channel import Channel, ChannelDataType

# Configure logging
logger = logging.getLogger(__name__)

CHANNELS_DEFAULT_PAGE_SIZE = 10_000
# TODO: There is a pagination issue API side when requesting multiple channels in single request.
# If all data points for all channels in a single request don't fit into a single page, then
# paging seems to omit all but a single channel. We can increase this batch size once that issue
# has been resolved. In the mean time each channel gets its own request.
REQUEST_BATCH_SIZE = 1


class ChannelsLowLevelClient(LowLevelClientBase):
    """
    Low-level client for the ChannelsAPI.

    This class provides a thin wrapper around the autogenerated bindings for the ChannelsAPI.
    """

    def __init__(self, grpc_client: GrpcClient):
        """
        Initialize the ChannelsLowLevelClient.

        Args:
            grpc_client: The gRPC client to use for making API calls.
        """
        self._grpc_client = grpc_client

    async def get_channel(self, channel_id: str) -> Channel:
        """
        Get a channel by channel_id.

        Args:
            channel_id: The channel ID to get.

        Returns:
            The Channel.

        Raises:
            ValueError: If channel_id is not provided.
        """
        if not channel_id:
            raise ValueError("channel_id must be provided")

        request = GetChannelRequest(channel_id=channel_id)
        response = await self._grpc_client.get_stub(ChannelServiceStub).GetChannel(request)
        grpc_channel = cast(GetChannelResponse, response).channel
        return Channel._from_proto(grpc_channel)

    async def list_channels(
        self,
        *,
        query_filter: str | None = None,
        page_size: int | None = None,
        page_token: str | None = None,
        order_by: str | None = None,
    ) -> tuple[list[Channel], str]:
        """
        List channels with optional filtering and pagination.

        Args:
            query_filter: A CEL filter string.
            page_size: The maximum number of channels to return.
            page_token: A page token for pagination.
            order_by: How to order the retrieved channels.

        Returns:
            A tuple of (channels, next_page_token).
        """

        request_kwargs: dict[str, Any] = {}
        if filter:
            request_kwargs["filter"] = query_filter
        if order_by:
            request_kwargs["order_by"] = order_by
        if page_size:
            request_kwargs["page_size"] = page_size
        if page_token:
            request_kwargs["page_token"] = page_token

        request = ListChannelsRequest(**request_kwargs)
        response = await self._grpc_client.get_stub(ChannelServiceStub).ListChannels(request)
        response = cast(ListChannelsResponse, response)

        channels = [Channel._from_proto(channel) for channel in response.channels]
        return channels, response.next_page_token

    async def list_all_channels(
        self,
        *,
        query_filter: str | None = None,
        order_by: str | None = None,
        max_results: int | None = None,
    ) -> list[Channel]:
        """
        List all channels with optional filtering.

        Args:
            query_filter: A CEL filter string.
            order_by: How to order the retrieved channels.
            max_results: Maximum number of results to return.

        Returns:
            A list of all matching channels.
        """
        # Channels default page size is 10,000 so lower it if we're passing max_results
        page_size = None
        if max_results is not None and max_results <= CHANNELS_DEFAULT_PAGE_SIZE:
            page_size = max_results
        return await self._handle_pagination(
            self.list_channels,
            kwargs={"query_filter": query_filter},
            page_size=page_size,
            order_by=order_by,
            max_results=max_results,
        )

    async def _get_data_impl(
        self,
        *,
        channel_ids: list[str],
        run_id: str | None = None,
        start_time: datetime | None = None,
        end_time: datetime,
        page_size: int | None = None,
        page_token: str | None = None,
        order_by: str | None = None,
    ) -> tuple[list[Any], str | None]:
        """
        Get the data for a channel during a run.
        """
        queries = [
            Query(channel=ChannelQuery(channel_id=channel_id, run_id=run_id))
            for channel_id in channel_ids
        ]

        request_kwargs: dict[str, Any] = {
            "queries": queries,
            "sample_ms": 0,
            "start_time": start_time,
            "end_time": end_time,
            "page_size": page_size,
            "page_token": page_token,
        }

        request = GetDataRequest(**request_kwargs)
        response = await self._grpc_client.get_stub(DataServiceStub).GetData(request)
        response = cast(GetDataResponse, response)
        return response.data, response.next_page_token

    async def get_channel_data(
        self,
        *,
        channel_ids: list[str],
        run_id: str | None = None,
        start_time: datetime | None = None,
        end_time: datetime | None = None,
        limit: int | None = None,
    ):
        """
        Get the data for a channel during a run.
        """
        # No data will be returned if end_time is not provided.
        end_time = end_time or datetime.now()

        tasks = []
        batch_size = REQUEST_BATCH_SIZE
        for i in range(0, len(channel_ids), batch_size):
            batch = channel_ids[i : i + batch_size]

            task = asyncio.create_task(
                self._handle_pagination(
                    self._get_data_impl,
                    kwargs={
                        "channel_ids": batch,
                        "run_id": run_id,
                        "start_time": start_time,
                        "end_time": end_time,
                    },
                    max_results=limit,
                )
            )
            tasks.append(task)

        data = await asyncio.gather(*tasks)
        # Flatten the data
        ret_data = {}
        for page in data:
            # print(page)
            for i, item in enumerate(page):
                # TODO: Merge
                name, np_array = try_deserialize_channel_data(item)
                if name not in ret_data:
                    ret_data[name] = np_array
                else:
                    ret_data[name] = np.concatenate((ret_data[name], np_array))

        return ret_data


def try_deserialize_channel_data(channel_data: Any):
    data_type = ChannelDataType.from_str(channel_data.type_url)
    if data_type is None:
        raise ValueError(f"Unknown data type: {channel_data.type_url}")

    proto_data_class = ChannelDataType.proto_data_class(data_type)
    proto_data_value = proto_data_class.FromString(channel_data.value)
    metadata = proto_data_value.metadata
    time_column = []
    value_column = []
    
    # TODO: One shot this
    for obj in proto_data_value.values:
        time_column.append(to_timestamp_nanos(obj.timestamp).to_numpy())
        value_column.append(obj.value)
    
    np_array = np.array([time_column, value_column]).T

    name = metadata.channel.name
    
    #TODO: Test bitfield
    
    return name, np_array
