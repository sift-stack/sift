"""Low-level wrapper for the DataImportAPI.

This module provides thin wrappers around the autogenerated bindings for the DataImportAPI.
It handles common concerns like error handling and retries.

It provides an asynchronous client for the DataImportAPI.
"""

from __future__ import annotations

from typing import Any, cast

from sift.data_imports.v2.data_imports_pb2 import (
    CreateDataImportFromUploadRequest,
    CreateDataImportFromUploadResponse,
    CreateDataImportFromUrlRequest,
    CreateDataImportFromUrlResponse,
    DataTypeKey,
    DetectConfigRequest,
    DetectConfigResponse,
    GetDataImportRequest,
    GetDataImportResponse,
    ListDataImportsRequest,
    ListDataImportsResponse,
    RetryDataImportRequest,
)
from sift.data_imports.v2.data_imports_pb2_grpc import DataImportServiceStub

from sift_client._internal.low_level_wrappers.base import (
    LowLevelClientBase,
)
from sift_client.sift_types.data_import import (
    Ch10Config,
    CsvConfig,
    DataImport,
    ParquetConfig,
    TDMSConfig,
)
from sift_client.transport import GrpcClient, WithGrpcClient


class DataImportsLowLevelClient(LowLevelClientBase, WithGrpcClient):
    """Low-level client for the DataImportAPI.

    This class provides a thin wrapper around the autogenerated bindings for the DataImportAPI.
    """

    def __init__(self, grpc_client: GrpcClient):
        """Initialize the DataImportsLowLevelClient.

        Args:
            grpc_client: The gRPC client to use for making API calls.
        """
        super().__init__(grpc_client)

    async def create_data_import_from_url(
        self,
        url: str,
        csv_config: CsvConfig | None = None,
        ch10_config: Ch10Config | None = None,
        tdms_config: TDMSConfig | None = None,
        parquet_config: ParquetConfig | None = None,
    ) -> str:
        """Create a data import from a URL.

        Args:
            url: The URL to import. HTTP and S3 URLs are supported.
            csv_config: Configuration for CSV files.
            ch10_config: Configuration for CH10 files.
            tdms_config: Configuration for TDMS files.
            parquet_config: Configuration for Parquet files.

        Returns:
            The data import ID.
        """
        request_kwargs: dict[str, Any] = {"url": url}
        if csv_config is not None:
            request_kwargs["csv_config"] = csv_config.to_proto()
        if ch10_config is not None:
            request_kwargs["ch10_config"] = ch10_config.to_proto()
        if tdms_config is not None:
            request_kwargs["tdms_config"] = tdms_config.to_proto()
        if parquet_config is not None:
            request_kwargs["parquet_config"] = parquet_config.to_proto()

        request = CreateDataImportFromUrlRequest(**request_kwargs)
        response = await self._grpc_client.get_stub(DataImportServiceStub).CreateDataImportFromUrl(
            request
        )
        response = cast("CreateDataImportFromUrlResponse", response)
        return response.data_import_id

    async def create_data_import_from_upload(
        self,
        csv_config: CsvConfig | None = None,
        ch10_config: Ch10Config | None = None,
        tdms_config: TDMSConfig | None = None,
        parquet_config: ParquetConfig | None = None,
    ) -> tuple[str, str]:
        """Create a data import from a file upload.

        Args:
            csv_config: Configuration for CSV files.
            ch10_config: Configuration for CH10 files.
            tdms_config: Configuration for TDMS files.
            parquet_config: Configuration for Parquet files.

        Returns:
            A tuple of (upload_url, data_import_id).
        """
        request_kwargs: dict[str, Any] = {}
        if csv_config is not None:
            request_kwargs["csv_config"] = csv_config.to_proto()
        if ch10_config is not None:
            request_kwargs["ch10_config"] = ch10_config.to_proto()
        if tdms_config is not None:
            request_kwargs["tdms_config"] = tdms_config.to_proto()
        if parquet_config is not None:
            request_kwargs["parquet_config"] = parquet_config.to_proto()

        request = CreateDataImportFromUploadRequest(**request_kwargs)
        response = await self._grpc_client.get_stub(
            DataImportServiceStub
        ).CreateDataImportFromUpload(request)
        response = cast("CreateDataImportFromUploadResponse", response)
        return response.upload_url, response.data_import_id

    async def detect_config(
        self, data: bytes, data_type: DataTypeKey.ValueType
    ) -> tuple[CsvConfig | None, ParquetConfig | None]:
        """Detect the configuration for a data import.

        Args:
            data: The data to detect the configuration for.
            data_type: The type of data (DataTypeKey enum value).

        Returns:
            A tuple of (csv_config, parquet_config) where one may be None.
        """
        request = DetectConfigRequest(data=data, type=data_type)
        response = await self._grpc_client.get_stub(DataImportServiceStub).DetectConfig(request)
        response = cast("DetectConfigResponse", response)

        csv_config = None
        if response.HasField("csv_config"):
            csv_config = CsvConfig.from_proto(response.csv_config)

        parquet_config = None
        if response.HasField("parquet_config"):
            parquet_config = ParquetConfig.from_proto(response.parquet_config)

        return csv_config, parquet_config

    async def get_data_import(self, data_import_id: str) -> DataImport:
        """Get a data import by ID.

        Args:
            data_import_id: The ID of the data import to retrieve.

        Returns:
            The data import.
        """
        request = GetDataImportRequest(data_import_id=data_import_id)
        response = await self._grpc_client.get_stub(DataImportServiceStub).GetDataImport(request)
        response = cast("GetDataImportResponse", response)
        return DataImport._from_proto(response.data_import)

    async def list_all_data_imports(
        self,
        query_filter: str | None = None,
        order_by: str | None = None,
        max_results: int | None = None,
        page_size: int | None = None,
    ) -> list[DataImport]:
        """List all data imports matching the given query.

        Args:
            query_filter: The CEL query filter.
            order_by: The field to order by.
            max_results: The maximum number of results to return.
            page_size: The number of results to return per page.

        Returns:
            A list of data imports matching the given query.
        """
        return await self._handle_pagination(
            self.list_data_imports,
            kwargs={"query_filter": query_filter},
            page_size=page_size,
            order_by=order_by,
            max_results=max_results,
        )

    async def list_data_imports(
        self,
        page_size: int | None = None,
        page_token: str | None = None,
        query_filter: str | None = None,
        order_by: str | None = None,
    ) -> tuple[list[DataImport], str]:
        """List data imports with pagination.

        Args:
            page_size: The number of results to return per page.
            page_token: The token for the next page.
            query_filter: The CEL query filter.
            order_by: The field to order by.

        Returns:
            A tuple of (data_imports, next_page_token).
        """
        request_kwargs: dict[str, Any] = {}
        if page_size is not None:
            request_kwargs["page_size"] = page_size
        if page_token is not None:
            request_kwargs["page_token"] = page_token
        if query_filter is not None:
            request_kwargs["filter"] = query_filter
        if order_by is not None:
            request_kwargs["order_by"] = order_by

        request = ListDataImportsRequest(**request_kwargs)
        response = await self._grpc_client.get_stub(DataImportServiceStub).ListDataImports(request)
        response = cast("ListDataImportsResponse", response)
        return (
            [DataImport._from_proto(di) for di in response.data_imports],
            response.next_page_token,
        )

    async def retry_data_import(self, data_import_id: str) -> None:
        """Retry a failed data import.

        Args:
            data_import_id: The ID of the data import to retry.
        """
        request = RetryDataImportRequest(data_import_id=data_import_id)
        await self._grpc_client.get_stub(DataImportServiceStub).RetryDataImport(request)
