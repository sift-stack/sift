"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""

import builtins
import collections.abc
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import google.protobuf.timestamp_pb2
import sift.common.type.v1.channel_config_pb2
import sys
import typing

if sys.version_info >= (3, 10):
    import typing as typing_extensions
else:
    import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

class _TimeFormat:
    ValueType = typing.NewType("ValueType", builtins.int)
    V: typing_extensions.TypeAlias = ValueType

class _TimeFormatEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_TimeFormat.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    TIME_FORMAT_UNSPECIFIED: _TimeFormat.ValueType  # 0
    TIME_FORMAT_RELATIVE_NANOSECONDS: _TimeFormat.ValueType  # 1
    TIME_FORMAT_RELATIVE_MICROSECONDS: _TimeFormat.ValueType  # 2
    TIME_FORMAT_RELATIVE_MILLISECONDS: _TimeFormat.ValueType  # 3
    TIME_FORMAT_RELATIVE_SECONDS: _TimeFormat.ValueType  # 4
    TIME_FORMAT_RELATIVE_MINUTES: _TimeFormat.ValueType  # 5
    TIME_FORMAT_RELATIVE_HOURS: _TimeFormat.ValueType  # 6
    TIME_FORMAT_ABSOLUTE_RFC3339: _TimeFormat.ValueType  # 10
    TIME_FORMAT_ABSOLUTE_DATETIME: _TimeFormat.ValueType  # 11
    TIME_FORMAT_ABSOLUTE_UNIX_SECONDS: _TimeFormat.ValueType  # 12
    TIME_FORMAT_ABSOLUTE_UNIX_MILLISECONDS: _TimeFormat.ValueType  # 13
    TIME_FORMAT_ABSOLUTE_UNIX_MICROSECONDS: _TimeFormat.ValueType  # 14
    TIME_FORMAT_ABSOLUTE_UNIX_NANOSECONDS: _TimeFormat.ValueType  # 15

class TimeFormat(_TimeFormat, metaclass=_TimeFormatEnumTypeWrapper): ...

TIME_FORMAT_UNSPECIFIED: TimeFormat.ValueType  # 0
TIME_FORMAT_RELATIVE_NANOSECONDS: TimeFormat.ValueType  # 1
TIME_FORMAT_RELATIVE_MICROSECONDS: TimeFormat.ValueType  # 2
TIME_FORMAT_RELATIVE_MILLISECONDS: TimeFormat.ValueType  # 3
TIME_FORMAT_RELATIVE_SECONDS: TimeFormat.ValueType  # 4
TIME_FORMAT_RELATIVE_MINUTES: TimeFormat.ValueType  # 5
TIME_FORMAT_RELATIVE_HOURS: TimeFormat.ValueType  # 6
TIME_FORMAT_ABSOLUTE_RFC3339: TimeFormat.ValueType  # 10
TIME_FORMAT_ABSOLUTE_DATETIME: TimeFormat.ValueType  # 11
TIME_FORMAT_ABSOLUTE_UNIX_SECONDS: TimeFormat.ValueType  # 12
TIME_FORMAT_ABSOLUTE_UNIX_MILLISECONDS: TimeFormat.ValueType  # 13
TIME_FORMAT_ABSOLUTE_UNIX_MICROSECONDS: TimeFormat.ValueType  # 14
TIME_FORMAT_ABSOLUTE_UNIX_NANOSECONDS: TimeFormat.ValueType  # 15
global___TimeFormat = TimeFormat

class _DataTypeKey:
    ValueType = typing.NewType("ValueType", builtins.int)
    V: typing_extensions.TypeAlias = ValueType

class _DataTypeKeyEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_DataTypeKey.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    DATA_TYPE_KEY_UNSPECIFIED: _DataTypeKey.ValueType  # 0
    DATA_TYPE_KEY_CSV: _DataTypeKey.ValueType  # 1
    DATA_TYPE_KEY_TDMS: _DataTypeKey.ValueType  # 2
    DATA_TYPE_KEY_CH10: _DataTypeKey.ValueType  # 3
    DATA_TYPE_KEY_PARQUET_FLATDATASET: _DataTypeKey.ValueType  # 4

class DataTypeKey(_DataTypeKey, metaclass=_DataTypeKeyEnumTypeWrapper): ...

DATA_TYPE_KEY_UNSPECIFIED: DataTypeKey.ValueType  # 0
DATA_TYPE_KEY_CSV: DataTypeKey.ValueType  # 1
DATA_TYPE_KEY_TDMS: DataTypeKey.ValueType  # 2
DATA_TYPE_KEY_CH10: DataTypeKey.ValueType  # 3
DATA_TYPE_KEY_PARQUET_FLATDATASET: DataTypeKey.ValueType  # 4
global___DataTypeKey = DataTypeKey

class _ParquetComplexTypesImportMode:
    ValueType = typing.NewType("ValueType", builtins.int)
    V: typing_extensions.TypeAlias = ValueType

class _ParquetComplexTypesImportModeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_ParquetComplexTypesImportMode.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    PARQUET_COMPLEX_TYPES_IMPORT_MODE_UNSPECIFIED: _ParquetComplexTypesImportMode.ValueType  # 0
    PARQUET_COMPLEX_TYPES_IMPORT_MODE_IGNORE: _ParquetComplexTypesImportMode.ValueType  # 1
    """Ignore complex types and do not ingest them."""
    PARQUET_COMPLEX_TYPES_IMPORT_MODE_BOTH: _ParquetComplexTypesImportMode.ValueType  # 2
    """Import complex types as both Arrow bytes and JSON strings."""
    PARQUET_COMPLEX_TYPES_IMPORT_MODE_STRING: _ParquetComplexTypesImportMode.ValueType  # 3
    """Import complex types as only JSON strings."""
    PARQUET_COMPLEX_TYPES_IMPORT_MODE_BYTES: _ParquetComplexTypesImportMode.ValueType  # 4
    """Import complex types as only Arrow bytes."""

class ParquetComplexTypesImportMode(_ParquetComplexTypesImportMode, metaclass=_ParquetComplexTypesImportModeEnumTypeWrapper): ...

PARQUET_COMPLEX_TYPES_IMPORT_MODE_UNSPECIFIED: ParquetComplexTypesImportMode.ValueType  # 0
PARQUET_COMPLEX_TYPES_IMPORT_MODE_IGNORE: ParquetComplexTypesImportMode.ValueType  # 1
"""Ignore complex types and do not ingest them."""
PARQUET_COMPLEX_TYPES_IMPORT_MODE_BOTH: ParquetComplexTypesImportMode.ValueType  # 2
"""Import complex types as both Arrow bytes and JSON strings."""
PARQUET_COMPLEX_TYPES_IMPORT_MODE_STRING: ParquetComplexTypesImportMode.ValueType  # 3
"""Import complex types as only JSON strings."""
PARQUET_COMPLEX_TYPES_IMPORT_MODE_BYTES: ParquetComplexTypesImportMode.ValueType  # 4
"""Import complex types as only Arrow bytes."""
global___ParquetComplexTypesImportMode = ParquetComplexTypesImportMode

class _DataImportStatus:
    ValueType = typing.NewType("ValueType", builtins.int)
    V: typing_extensions.TypeAlias = ValueType

class _DataImportStatusEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_DataImportStatus.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    DATA_IMPORT_STATUS_UNSPECIFIED: _DataImportStatus.ValueType  # 0
    DATA_IMPORT_STATUS_PENDING: _DataImportStatus.ValueType  # 1
    DATA_IMPORT_STATUS_IN_PROGRESS: _DataImportStatus.ValueType  # 2
    DATA_IMPORT_STATUS_SUCCEEDED: _DataImportStatus.ValueType  # 3
    DATA_IMPORT_STATUS_FAILED: _DataImportStatus.ValueType  # 4

class DataImportStatus(_DataImportStatus, metaclass=_DataImportStatusEnumTypeWrapper): ...

DATA_IMPORT_STATUS_UNSPECIFIED: DataImportStatus.ValueType  # 0
DATA_IMPORT_STATUS_PENDING: DataImportStatus.ValueType  # 1
DATA_IMPORT_STATUS_IN_PROGRESS: DataImportStatus.ValueType  # 2
DATA_IMPORT_STATUS_SUCCEEDED: DataImportStatus.ValueType  # 3
DATA_IMPORT_STATUS_FAILED: DataImportStatus.ValueType  # 4
global___DataImportStatus = DataImportStatus

@typing.final
class CreateDataImportFromUrlRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    URL_FIELD_NUMBER: builtins.int
    CSV_CONFIG_FIELD_NUMBER: builtins.int
    CH10_CONFIG_FIELD_NUMBER: builtins.int
    TDMS_CONFIG_FIELD_NUMBER: builtins.int
    PARQUET_CONFIG_FIELD_NUMBER: builtins.int
    url: builtins.str
    """The url to import. HTTP and S3 urls are supported.
    If you need to import non-public S3 objects, please contact Sift to set that up.
    """
    @property
    def csv_config(self) -> global___CsvConfig: ...
    @property
    def ch10_config(self) -> global___Ch10Config: ...
    @property
    def tdms_config(self) -> global___TDMSConfig: ...
    @property
    def parquet_config(self) -> global___ParquetConfig: ...
    def __init__(
        self,
        *,
        url: builtins.str = ...,
        csv_config: global___CsvConfig | None = ...,
        ch10_config: global___Ch10Config | None = ...,
        tdms_config: global___TDMSConfig | None = ...,
        parquet_config: global___ParquetConfig | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["ch10_config", b"ch10_config", "csv_config", b"csv_config", "parquet_config", b"parquet_config", "tdms_config", b"tdms_config"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["ch10_config", b"ch10_config", "csv_config", b"csv_config", "parquet_config", b"parquet_config", "tdms_config", b"tdms_config", "url", b"url"]) -> None: ...

global___CreateDataImportFromUrlRequest = CreateDataImportFromUrlRequest

@typing.final
class CreateDataImportFromUrlResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    DATA_IMPORT_ID_FIELD_NUMBER: builtins.int
    data_import_id: builtins.str
    def __init__(
        self,
        *,
        data_import_id: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["data_import_id", b"data_import_id"]) -> None: ...

global___CreateDataImportFromUrlResponse = CreateDataImportFromUrlResponse

@typing.final
class GetDataImportRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    DATA_IMPORT_ID_FIELD_NUMBER: builtins.int
    data_import_id: builtins.str
    def __init__(
        self,
        *,
        data_import_id: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["data_import_id", b"data_import_id"]) -> None: ...

global___GetDataImportRequest = GetDataImportRequest

@typing.final
class GetDataImportResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    DATA_IMPORT_FIELD_NUMBER: builtins.int
    @property
    def data_import(self) -> global___DataImport: ...
    def __init__(
        self,
        *,
        data_import: global___DataImport | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["data_import", b"data_import"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["data_import", b"data_import"]) -> None: ...

global___GetDataImportResponse = GetDataImportResponse

@typing.final
class CreateDataImportFromUploadRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    CSV_CONFIG_FIELD_NUMBER: builtins.int
    CH10_CONFIG_FIELD_NUMBER: builtins.int
    TDMS_CONFIG_FIELD_NUMBER: builtins.int
    PARQUET_CONFIG_FIELD_NUMBER: builtins.int
    @property
    def csv_config(self) -> global___CsvConfig: ...
    @property
    def ch10_config(self) -> global___Ch10Config: ...
    @property
    def tdms_config(self) -> global___TDMSConfig: ...
    @property
    def parquet_config(self) -> global___ParquetConfig: ...
    def __init__(
        self,
        *,
        csv_config: global___CsvConfig | None = ...,
        ch10_config: global___Ch10Config | None = ...,
        tdms_config: global___TDMSConfig | None = ...,
        parquet_config: global___ParquetConfig | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["ch10_config", b"ch10_config", "csv_config", b"csv_config", "parquet_config", b"parquet_config", "tdms_config", b"tdms_config"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["ch10_config", b"ch10_config", "csv_config", b"csv_config", "parquet_config", b"parquet_config", "tdms_config", b"tdms_config"]) -> None: ...

global___CreateDataImportFromUploadRequest = CreateDataImportFromUploadRequest

@typing.final
class CreateDataImportFromUploadResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    UPLOAD_URL_FIELD_NUMBER: builtins.int
    DATA_IMPORT_ID_FIELD_NUMBER: builtins.int
    upload_url: builtins.str
    data_import_id: builtins.str
    def __init__(
        self,
        *,
        upload_url: builtins.str = ...,
        data_import_id: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["data_import_id", b"data_import_id", "upload_url", b"upload_url"]) -> None: ...

global___CreateDataImportFromUploadResponse = CreateDataImportFromUploadResponse

@typing.final
class CsvConfig(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    @typing.final
    class DataColumnsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: builtins.int
        @property
        def value(self) -> sift.common.type.v1.channel_config_pb2.ChannelConfig: ...
        def __init__(
            self,
            *,
            key: builtins.int = ...,
            value: sift.common.type.v1.channel_config_pb2.ChannelConfig | None = ...,
        ) -> None: ...
        def HasField(self, field_name: typing.Literal["value", b"value"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...

    ASSET_NAME_FIELD_NUMBER: builtins.int
    RUN_NAME_FIELD_NUMBER: builtins.int
    RUN_ID_FIELD_NUMBER: builtins.int
    FIRST_DATA_ROW_FIELD_NUMBER: builtins.int
    TIME_COLUMN_FIELD_NUMBER: builtins.int
    DATA_COLUMNS_FIELD_NUMBER: builtins.int
    NUM_ROWS_FIELD_NUMBER: builtins.int
    asset_name: builtins.str
    run_name: builtins.str
    run_id: builtins.str
    """The id of the run to add this data to. If set, `run_name` is ignored."""
    first_data_row: builtins.int
    """The first row to start reading as data. Can be used to skip header rows.
    The first row in the file is 1.
    """
    num_rows: builtins.int
    """This will be read on upload from the file if not set."""
    @property
    def time_column(self) -> global___CsvTimeColumn: ...
    @property
    def data_columns(self) -> google.protobuf.internal.containers.MessageMap[builtins.int, sift.common.type.v1.channel_config_pb2.ChannelConfig]:
        """A map from column number (1-indexed) to the channel configuration for that column."""

    def __init__(
        self,
        *,
        asset_name: builtins.str = ...,
        run_name: builtins.str = ...,
        run_id: builtins.str = ...,
        first_data_row: builtins.int = ...,
        time_column: global___CsvTimeColumn | None = ...,
        data_columns: collections.abc.Mapping[builtins.int, sift.common.type.v1.channel_config_pb2.ChannelConfig] | None = ...,
        num_rows: builtins.int | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["_num_rows", b"_num_rows", "_time_column", b"_time_column", "num_rows", b"num_rows", "time_column", b"time_column"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["_num_rows", b"_num_rows", "_time_column", b"_time_column", "asset_name", b"asset_name", "data_columns", b"data_columns", "first_data_row", b"first_data_row", "num_rows", b"num_rows", "run_id", b"run_id", "run_name", b"run_name", "time_column", b"time_column"]) -> None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal["_num_rows", b"_num_rows"]) -> typing.Literal["num_rows"] | None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal["_time_column", b"_time_column"]) -> typing.Literal["time_column"] | None: ...

global___CsvConfig = CsvConfig

@typing.final
class CsvTimeColumn(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    COLUMN_NUMBER_FIELD_NUMBER: builtins.int
    FORMAT_FIELD_NUMBER: builtins.int
    RELATIVE_START_TIME_FIELD_NUMBER: builtins.int
    column_number: builtins.int
    """The column number (1-indexed) of the time column."""
    format: global___TimeFormat.ValueType
    @property
    def relative_start_time(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
    def __init__(
        self,
        *,
        column_number: builtins.int = ...,
        format: global___TimeFormat.ValueType = ...,
        relative_start_time: google.protobuf.timestamp_pb2.Timestamp | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["_relative_start_time", b"_relative_start_time", "relative_start_time", b"relative_start_time"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["_relative_start_time", b"_relative_start_time", "column_number", b"column_number", "format", b"format", "relative_start_time", b"relative_start_time"]) -> None: ...
    def WhichOneof(self, oneof_group: typing.Literal["_relative_start_time", b"_relative_start_time"]) -> typing.Literal["relative_start_time"] | None: ...

global___CsvTimeColumn = CsvTimeColumn

@typing.final
class DetectConfigRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    DATA_FIELD_NUMBER: builtins.int
    TYPE_FIELD_NUMBER: builtins.int
    data: builtins.bytes
    type: global___DataTypeKey.ValueType
    def __init__(
        self,
        *,
        data: builtins.bytes = ...,
        type: global___DataTypeKey.ValueType = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["data", b"data", "type", b"type"]) -> None: ...

global___DetectConfigRequest = DetectConfigRequest

@typing.final
class DetectConfigResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    CSV_CONFIG_FIELD_NUMBER: builtins.int
    PARQUET_CONFIG_FIELD_NUMBER: builtins.int
    @property
    def csv_config(self) -> global___CsvConfig: ...
    @property
    def parquet_config(self) -> global___ParquetConfig: ...
    def __init__(
        self,
        *,
        csv_config: global___CsvConfig | None = ...,
        parquet_config: global___ParquetConfig | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["csv_config", b"csv_config", "parquet_config", b"parquet_config"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["csv_config", b"csv_config", "parquet_config", b"parquet_config"]) -> None: ...

global___DetectConfigResponse = DetectConfigResponse

@typing.final
class Ch10Config(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    ASSET_NAME_FIELD_NUMBER: builtins.int
    RUN_NAME_FIELD_NUMBER: builtins.int
    SCALE_VALUES_FIELD_NUMBER: builtins.int
    asset_name: builtins.str
    run_name: builtins.str
    scale_values: builtins.bool
    def __init__(
        self,
        *,
        asset_name: builtins.str = ...,
        run_name: builtins.str = ...,
        scale_values: builtins.bool = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["asset_name", b"asset_name", "run_name", b"run_name", "scale_values", b"scale_values"]) -> None: ...

global___Ch10Config = Ch10Config

@typing.final
class TDMSConfig(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    ASSET_NAME_FIELD_NUMBER: builtins.int
    RUN_NAME_FIELD_NUMBER: builtins.int
    START_TIME_OVERRIDE_FIELD_NUMBER: builtins.int
    FILE_SIZE_FIELD_NUMBER: builtins.int
    RUN_ID_FIELD_NUMBER: builtins.int
    asset_name: builtins.str
    run_name: builtins.str
    file_size: builtins.int
    """The file size in bytes.
    If the file has truncated chunks, this will be required to pass validation.
    """
    run_id: builtins.str
    """The id of the run to add this data to. If set, `run_name` is ignored."""
    @property
    def start_time_override(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Override the wf_start_time metadata field for all channels.
        Useful if your waveform channels have wf_increment but no wf_start_time (Veristand is guilty of this).
        """

    def __init__(
        self,
        *,
        asset_name: builtins.str = ...,
        run_name: builtins.str = ...,
        start_time_override: google.protobuf.timestamp_pb2.Timestamp | None = ...,
        file_size: builtins.int | None = ...,
        run_id: builtins.str = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["_file_size", b"_file_size", "file_size", b"file_size", "start_time_override", b"start_time_override"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["_file_size", b"_file_size", "asset_name", b"asset_name", "file_size", b"file_size", "run_id", b"run_id", "run_name", b"run_name", "start_time_override", b"start_time_override"]) -> None: ...
    def WhichOneof(self, oneof_group: typing.Literal["_file_size", b"_file_size"]) -> typing.Literal["file_size"] | None: ...

global___TDMSConfig = TDMSConfig

@typing.final
class ParquetTimeColumn(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    PATH_FIELD_NUMBER: builtins.int
    FORMAT_FIELD_NUMBER: builtins.int
    RELATIVE_START_TIME_FIELD_NUMBER: builtins.int
    path: builtins.str
    format: global___TimeFormat.ValueType
    @property
    def relative_start_time(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
    def __init__(
        self,
        *,
        path: builtins.str = ...,
        format: global___TimeFormat.ValueType = ...,
        relative_start_time: google.protobuf.timestamp_pb2.Timestamp | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["_relative_start_time", b"_relative_start_time", "relative_start_time", b"relative_start_time"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["_relative_start_time", b"_relative_start_time", "format", b"format", "path", b"path", "relative_start_time", b"relative_start_time"]) -> None: ...
    def WhichOneof(self, oneof_group: typing.Literal["_relative_start_time", b"_relative_start_time"]) -> typing.Literal["relative_start_time"] | None: ...

global___ParquetTimeColumn = ParquetTimeColumn

@typing.final
class ParquetDataColumn(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    PATH_FIELD_NUMBER: builtins.int
    CHANNEL_CONFIG_FIELD_NUMBER: builtins.int
    path: builtins.str
    @property
    def channel_config(self) -> sift.common.type.v1.channel_config_pb2.ChannelConfig: ...
    def __init__(
        self,
        *,
        path: builtins.str = ...,
        channel_config: sift.common.type.v1.channel_config_pb2.ChannelConfig | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["channel_config", b"channel_config"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["channel_config", b"channel_config", "path", b"path"]) -> None: ...

global___ParquetDataColumn = ParquetDataColumn

@typing.final
class ParquetFlatDatasetConfig(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    TIME_COLUMN_FIELD_NUMBER: builtins.int
    DATA_COLUMNS_FIELD_NUMBER: builtins.int
    @property
    def time_column(self) -> global___ParquetTimeColumn: ...
    @property
    def data_columns(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ParquetDataColumn]: ...
    def __init__(
        self,
        *,
        time_column: global___ParquetTimeColumn | None = ...,
        data_columns: collections.abc.Iterable[global___ParquetDataColumn] | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["time_column", b"time_column"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["data_columns", b"data_columns", "time_column", b"time_column"]) -> None: ...

global___ParquetFlatDatasetConfig = ParquetFlatDatasetConfig

@typing.final
class ParquetConfig(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    ASSET_NAME_FIELD_NUMBER: builtins.int
    RUN_NAME_FIELD_NUMBER: builtins.int
    RUN_ID_FIELD_NUMBER: builtins.int
    FLAT_DATASET_FIELD_NUMBER: builtins.int
    FOOTER_OFFSET_FIELD_NUMBER: builtins.int
    FOOTER_LENGTH_FIELD_NUMBER: builtins.int
    COMPLEX_TYPES_IMPORT_MODE_FIELD_NUMBER: builtins.int
    asset_name: builtins.str
    run_name: builtins.str
    run_id: builtins.str
    """The id of the run to add this data to. If set, `run_name` is ignored."""
    footer_offset: builtins.int
    footer_length: builtins.int
    complex_types_import_mode: global___ParquetComplexTypesImportMode.ValueType
    @property
    def flat_dataset(self) -> global___ParquetFlatDatasetConfig: ...
    def __init__(
        self,
        *,
        asset_name: builtins.str = ...,
        run_name: builtins.str = ...,
        run_id: builtins.str = ...,
        flat_dataset: global___ParquetFlatDatasetConfig | None = ...,
        footer_offset: builtins.int = ...,
        footer_length: builtins.int = ...,
        complex_types_import_mode: global___ParquetComplexTypesImportMode.ValueType = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["config", b"config", "flat_dataset", b"flat_dataset"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["asset_name", b"asset_name", "complex_types_import_mode", b"complex_types_import_mode", "config", b"config", "flat_dataset", b"flat_dataset", "footer_length", b"footer_length", "footer_offset", b"footer_offset", "run_id", b"run_id", "run_name", b"run_name"]) -> None: ...
    def WhichOneof(self, oneof_group: typing.Literal["config", b"config"]) -> typing.Literal["flat_dataset"] | None: ...

global___ParquetConfig = ParquetConfig

@typing.final
class DataImport(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    DATA_IMPORT_ID_FIELD_NUMBER: builtins.int
    SOURCE_URL_FIELD_NUMBER: builtins.int
    STATUS_FIELD_NUMBER: builtins.int
    ERROR_MESSAGE_FIELD_NUMBER: builtins.int
    CREATED_DATE_FIELD_NUMBER: builtins.int
    MODIFIED_DATE_FIELD_NUMBER: builtins.int
    CSV_CONFIG_FIELD_NUMBER: builtins.int
    CH10_CONFIG_FIELD_NUMBER: builtins.int
    TDMS_CONFIG_FIELD_NUMBER: builtins.int
    PARQUET_CONFIG_FIELD_NUMBER: builtins.int
    RUN_ID_FIELD_NUMBER: builtins.int
    REPORT_ID_FIELD_NUMBER: builtins.int
    ASSET_ID_FIELD_NUMBER: builtins.int
    DATA_START_TIME_FIELD_NUMBER: builtins.int
    DATA_STOP_TIME_FIELD_NUMBER: builtins.int
    data_import_id: builtins.str
    source_url: builtins.str
    status: global___DataImportStatus.ValueType
    error_message: builtins.str
    run_id: builtins.str
    """The run id will be set if the data import ingests to a run once the run is available."""
    report_id: builtins.str
    """The report id will be set if the data import creates a report once the report is available."""
    asset_id: builtins.str
    @property
    def created_date(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
    @property
    def modified_date(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
    @property
    def csv_config(self) -> global___CsvConfig: ...
    @property
    def ch10_config(self) -> global___Ch10Config: ...
    @property
    def tdms_config(self) -> global___TDMSConfig: ...
    @property
    def parquet_config(self) -> global___ParquetConfig: ...
    @property
    def data_start_time(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
    @property
    def data_stop_time(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
    def __init__(
        self,
        *,
        data_import_id: builtins.str = ...,
        source_url: builtins.str = ...,
        status: global___DataImportStatus.ValueType = ...,
        error_message: builtins.str = ...,
        created_date: google.protobuf.timestamp_pb2.Timestamp | None = ...,
        modified_date: google.protobuf.timestamp_pb2.Timestamp | None = ...,
        csv_config: global___CsvConfig | None = ...,
        ch10_config: global___Ch10Config | None = ...,
        tdms_config: global___TDMSConfig | None = ...,
        parquet_config: global___ParquetConfig | None = ...,
        run_id: builtins.str | None = ...,
        report_id: builtins.str | None = ...,
        asset_id: builtins.str | None = ...,
        data_start_time: google.protobuf.timestamp_pb2.Timestamp | None = ...,
        data_stop_time: google.protobuf.timestamp_pb2.Timestamp | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["_asset_id", b"_asset_id", "_data_start_time", b"_data_start_time", "_data_stop_time", b"_data_stop_time", "_report_id", b"_report_id", "_run_id", b"_run_id", "asset_id", b"asset_id", "ch10_config", b"ch10_config", "created_date", b"created_date", "csv_config", b"csv_config", "data_start_time", b"data_start_time", "data_stop_time", b"data_stop_time", "modified_date", b"modified_date", "parquet_config", b"parquet_config", "report_id", b"report_id", "run_id", b"run_id", "tdms_config", b"tdms_config"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["_asset_id", b"_asset_id", "_data_start_time", b"_data_start_time", "_data_stop_time", b"_data_stop_time", "_report_id", b"_report_id", "_run_id", b"_run_id", "asset_id", b"asset_id", "ch10_config", b"ch10_config", "created_date", b"created_date", "csv_config", b"csv_config", "data_import_id", b"data_import_id", "data_start_time", b"data_start_time", "data_stop_time", b"data_stop_time", "error_message", b"error_message", "modified_date", b"modified_date", "parquet_config", b"parquet_config", "report_id", b"report_id", "run_id", b"run_id", "source_url", b"source_url", "status", b"status", "tdms_config", b"tdms_config"]) -> None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal["_asset_id", b"_asset_id"]) -> typing.Literal["asset_id"] | None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal["_data_start_time", b"_data_start_time"]) -> typing.Literal["data_start_time"] | None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal["_data_stop_time", b"_data_stop_time"]) -> typing.Literal["data_stop_time"] | None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal["_report_id", b"_report_id"]) -> typing.Literal["report_id"] | None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal["_run_id", b"_run_id"]) -> typing.Literal["run_id"] | None: ...

global___DataImport = DataImport

@typing.final
class ListDataImportsRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    PAGE_SIZE_FIELD_NUMBER: builtins.int
    PAGE_TOKEN_FIELD_NUMBER: builtins.int
    FILTER_FIELD_NUMBER: builtins.int
    ORDER_BY_FIELD_NUMBER: builtins.int
    page_size: builtins.int
    """The maximum number of data imports to return. The service may return fewer than this value.
    If unspecified, at most 50 data imports will be returned. The maximum value is 1000; values above
    1000 will be coerced to 1000. Optional.
    """
    page_token: builtins.str
    """A page token, received from a previous `ListDataImports` call.
    Provide this to retrieve the subsequent page.
    When paginating, all other parameters provided to `ListDataImports` must match
    the call that provided the page token. Optional.
    """
    filter: builtins.str
    """A [Common Expression Language (CEL)](https://github.com/google/cel-spec) filter string.
    Available fields to filter by are `data_import_id`, `source_url`, `status`.
    For further information about how to use CELs, please refer to [this guide](https://github.com/google/cel-spec/blob/master/doc/langdef.md#standard-definitions).
    """
    order_by: builtins.str
    """How to order the retrieved data imports. Formatted as a comma-separated string i.e. "FIELD_NAME[ desc],...".
    Available fields to order_by are `created_date` and `modified_date`.
    If left empty, items are ordered by `created_date` in ascending order (oldest-first).
    For more information about the format of this field, read [this](https://google.aip.dev/132#ordering)
    Example: "created_date desc,modified_date"
    """
    def __init__(
        self,
        *,
        page_size: builtins.int = ...,
        page_token: builtins.str = ...,
        filter: builtins.str = ...,
        order_by: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["filter", b"filter", "order_by", b"order_by", "page_size", b"page_size", "page_token", b"page_token"]) -> None: ...

global___ListDataImportsRequest = ListDataImportsRequest

@typing.final
class ListDataImportsResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    DATA_IMPORTS_FIELD_NUMBER: builtins.int
    NEXT_PAGE_TOKEN_FIELD_NUMBER: builtins.int
    next_page_token: builtins.str
    @property
    def data_imports(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___DataImport]: ...
    def __init__(
        self,
        *,
        data_imports: collections.abc.Iterable[global___DataImport] | None = ...,
        next_page_token: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["data_imports", b"data_imports", "next_page_token", b"next_page_token"]) -> None: ...

global___ListDataImportsResponse = ListDataImportsResponse

@typing.final
class RetryDataImportRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    DATA_IMPORT_ID_FIELD_NUMBER: builtins.int
    data_import_id: builtins.str
    """data_import_id is the id of the data import to retry.
    You can only retry an import that is a "url" based import (created with CreateDataImportFromUrl) and is in a failed state.
    """
    def __init__(
        self,
        *,
        data_import_id: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["data_import_id", b"data_import_id"]) -> None: ...

global___RetryDataImportRequest = RetryDataImportRequest

@typing.final
class RetryDataImportResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    def __init__(
        self,
    ) -> None: ...

global___RetryDataImportResponse = RetryDataImportResponse
