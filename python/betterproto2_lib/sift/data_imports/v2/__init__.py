# Generated by the protocol buffer compiler.  DO NOT EDIT!
# sources: sift/data_imports/v2/data_imports.proto
# plugin: python-betterproto2
# This file has been @generated

__all__ = (
    "DataImportStatus",
    "TimeFormat",
    "Ch10Config",
    "CreateDataImportFromUploadRequest",
    "CreateDataImportFromUploadResponse",
    "CreateDataImportFromUrlRequest",
    "CreateDataImportFromUrlResponse",
    "CsvConfig",
    "CsvTimeColumn",
    "DataImport",
    "DetectConfigRequest",
    "DetectConfigResponse",
    "GetDataImportRequest",
    "GetDataImportResponse",
    "ListDataImportsRequest",
    "ListDataImportsResponse",
    "RetryDataImportRequest",
    "RetryDataImportResponse",
    "TdmsConfig",
    "DataImportServiceStub",
    "DataImportServiceBase",
)

import datetime
from dataclasses import dataclass
from typing import TYPE_CHECKING

import betterproto2
import grpc
import grpclib
from betterproto2.grpc.grpclib_server import ServiceBase

from ....message_pool import default_message_pool

if TYPE_CHECKING:
    import grpclib.server
    from betterproto2.grpc.grpclib_client import MetadataLike
    from grpclib.metadata import Deadline

betterproto2.check_compiler_version("0.4.0")


class DataImportStatus(betterproto2.Enum):
    UNSPECIFIED = 0

    PENDING = 1

    IN_PROGRESS = 2

    SUCCEEDED = 3

    FAILED = 4


class TimeFormat(betterproto2.Enum):
    UNSPECIFIED = 0

    RELATIVE_NANOSECONDS = 1

    RELATIVE_MICROSECONDS = 2

    RELATIVE_MILLISECONDS = 3

    RELATIVE_SECONDS = 4

    RELATIVE_MINUTES = 5

    RELATIVE_HOURS = 6

    ABSOLUTE_RFC3339 = 10

    ABSOLUTE_DATETIME = 11

    ABSOLUTE_UNIX_SECONDS = 12

    ABSOLUTE_UNIX_MILLISECONDS = 13

    ABSOLUTE_UNIX_MICROSECONDS = 14

    ABSOLUTE_UNIX_NANOSECONDS = 15


@dataclass(eq=False, repr=False)
class Ch10Config(betterproto2.Message):
    asset_name: "str" = betterproto2.field(1, betterproto2.TYPE_STRING)

    run_name: "str" = betterproto2.field(2, betterproto2.TYPE_STRING)

    scale_values: "bool" = betterproto2.field(3, betterproto2.TYPE_BOOL)


default_message_pool.register_message("sift.data_imports.v2", "Ch10Config", Ch10Config)


@dataclass(eq=False, repr=False)
class CreateDataImportFromUploadRequest(betterproto2.Message):
    csv_config: "CsvConfig | None" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, optional=True
    )

    ch10_config: "Ch10Config | None" = betterproto2.field(
        3, betterproto2.TYPE_MESSAGE, optional=True
    )

    tdms_config: "TdmsConfig | None" = betterproto2.field(
        4, betterproto2.TYPE_MESSAGE, optional=True
    )


default_message_pool.register_message(
    "sift.data_imports.v2",
    "CreateDataImportFromUploadRequest",
    CreateDataImportFromUploadRequest,
)


@dataclass(eq=False, repr=False)
class CreateDataImportFromUploadResponse(betterproto2.Message):
    upload_url: "str" = betterproto2.field(1, betterproto2.TYPE_STRING)

    data_import_id: "str" = betterproto2.field(2, betterproto2.TYPE_STRING)


default_message_pool.register_message(
    "sift.data_imports.v2",
    "CreateDataImportFromUploadResponse",
    CreateDataImportFromUploadResponse,
)


@dataclass(eq=False, repr=False)
class CreateDataImportFromUrlRequest(betterproto2.Message):
    url: "str" = betterproto2.field(1, betterproto2.TYPE_STRING)
    """
    The url to import. HTTP and S3 urls are supported.
    If you need to import non-public S3 objects, please contact Sift to set that up.
    """

    csv_config: "CsvConfig | None" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, optional=True
    )

    ch10_config: "Ch10Config | None" = betterproto2.field(
        3, betterproto2.TYPE_MESSAGE, optional=True
    )

    tdms_config: "TdmsConfig | None" = betterproto2.field(
        4, betterproto2.TYPE_MESSAGE, optional=True
    )


default_message_pool.register_message(
    "sift.data_imports.v2",
    "CreateDataImportFromUrlRequest",
    CreateDataImportFromUrlRequest,
)


@dataclass(eq=False, repr=False)
class CreateDataImportFromUrlResponse(betterproto2.Message):
    data_import_id: "str" = betterproto2.field(1, betterproto2.TYPE_STRING)


default_message_pool.register_message(
    "sift.data_imports.v2",
    "CreateDataImportFromUrlResponse",
    CreateDataImportFromUrlResponse,
)


@dataclass(eq=False, repr=False)
class CsvConfig(betterproto2.Message):
    asset_name: "str" = betterproto2.field(1, betterproto2.TYPE_STRING)

    run_name: "str" = betterproto2.field(2, betterproto2.TYPE_STRING)

    run_id: "str" = betterproto2.field(3, betterproto2.TYPE_STRING)
    """
    The id of the run to add this data to. If set, `run_name` is ignored.
    """

    first_data_row: "int" = betterproto2.field(4, betterproto2.TYPE_UINT32)
    """
    The first row to start reading as data. Can be used to skip header rows.
    The first row in the file is 1.
    """

    time_column: "CsvTimeColumn | None" = betterproto2.field(
        5, betterproto2.TYPE_MESSAGE, optional=True
    )

    data_columns: "dict[int, __common__type__v1__.ChannelConfig]" = betterproto2.field(
        6,
        betterproto2.TYPE_MAP,
        map_types=(betterproto2.TYPE_UINT32, betterproto2.TYPE_MESSAGE),
    )
    """
    A map from column number (1-indexed) to the channel configuration for that column.
    """


default_message_pool.register_message("sift.data_imports.v2", "CsvConfig", CsvConfig)


@dataclass(eq=False, repr=False)
class CsvTimeColumn(betterproto2.Message):
    column_number: "int" = betterproto2.field(1, betterproto2.TYPE_UINT32)
    """
    The column number (1-indexed) of the time column.
    """

    format: "TimeFormat" = betterproto2.field(
        2, betterproto2.TYPE_ENUM, default_factory=lambda: TimeFormat(0)
    )

    relative_start_time: "datetime.datetime | None" = betterproto2.field(
        3, betterproto2.TYPE_MESSAGE, optional=True
    )


default_message_pool.register_message(
    "sift.data_imports.v2", "CsvTimeColumn", CsvTimeColumn
)


@dataclass(eq=False, repr=False)
class DataImport(betterproto2.Message):
    data_import_id: "str" = betterproto2.field(1, betterproto2.TYPE_STRING)

    source_url: "str" = betterproto2.field(3, betterproto2.TYPE_STRING)

    status: "DataImportStatus" = betterproto2.field(
        4, betterproto2.TYPE_ENUM, default_factory=lambda: DataImportStatus(0)
    )

    error_message: "str" = betterproto2.field(5, betterproto2.TYPE_STRING)

    created_date: "datetime.datetime | None" = betterproto2.field(
        7, betterproto2.TYPE_MESSAGE, optional=True
    )

    modified_date: "datetime.datetime | None" = betterproto2.field(
        8, betterproto2.TYPE_MESSAGE, optional=True
    )

    csv_config: "CsvConfig | None" = betterproto2.field(
        6, betterproto2.TYPE_MESSAGE, optional=True
    )

    ch10_config: "Ch10Config | None" = betterproto2.field(
        9, betterproto2.TYPE_MESSAGE, optional=True
    )

    tdms_config: "TdmsConfig | None" = betterproto2.field(
        10, betterproto2.TYPE_MESSAGE, optional=True
    )


default_message_pool.register_message("sift.data_imports.v2", "DataImport", DataImport)


@dataclass(eq=False, repr=False)
class DetectConfigRequest(betterproto2.Message):
    data: "bytes" = betterproto2.field(1, betterproto2.TYPE_BYTES)


default_message_pool.register_message(
    "sift.data_imports.v2", "DetectConfigRequest", DetectConfigRequest
)


@dataclass(eq=False, repr=False)
class DetectConfigResponse(betterproto2.Message):
    csv_config: "CsvConfig | None" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, optional=True
    )


default_message_pool.register_message(
    "sift.data_imports.v2", "DetectConfigResponse", DetectConfigResponse
)


@dataclass(eq=False, repr=False)
class GetDataImportRequest(betterproto2.Message):
    data_import_id: "str" = betterproto2.field(1, betterproto2.TYPE_STRING)


default_message_pool.register_message(
    "sift.data_imports.v2", "GetDataImportRequest", GetDataImportRequest
)


@dataclass(eq=False, repr=False)
class GetDataImportResponse(betterproto2.Message):
    data_import: "DataImport | None" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, optional=True
    )


default_message_pool.register_message(
    "sift.data_imports.v2", "GetDataImportResponse", GetDataImportResponse
)


@dataclass(eq=False, repr=False)
class ListDataImportsRequest(betterproto2.Message):
    page_size: "int" = betterproto2.field(1, betterproto2.TYPE_UINT32)
    """
    The maximum number of data imports to return. The service may return fewer than this value.
    If unspecified, at most 50 data imports will be returned. The maximum value is 1000; values above
    1000 will be coerced to 1000. Optional.
    """

    page_token: "str" = betterproto2.field(2, betterproto2.TYPE_STRING)
    """
    A page token, received from a previous `ListDataImports` call.
    Provide this to retrieve the subsequent page.
    When paginating, all other parameters provided to `ListDataImports` must match
    the call that provided the page token. Optional.
    """

    filter: "str" = betterproto2.field(3, betterproto2.TYPE_STRING)
    """
    A [Common Expression Language (CEL)](https://github.com/google/cel-spec) filter string.
    Available fields to filter by are `data_import_id`, `source_url`, `status`.
    For further information about how to use CELs, please refer to [this guide](https://github.com/google/cel-spec/blob/master/doc/langdef.md#standard-definitions).
    """

    order_by: "str" = betterproto2.field(4, betterproto2.TYPE_STRING)
    """
    How to order the retrieved data imports. Formatted as a comma-separated string i.e. "FIELD_NAME[ desc],...".
    Available fields to order_by are `created_date` and `modified_date`.
    If left empty, items are ordered by `created_date` in ascending order (oldest-first).
    For more information about the format of this field, read [this](https://google.aip.dev/132#ordering)
    Example: "created_date desc,modified_date"
    """


default_message_pool.register_message(
    "sift.data_imports.v2", "ListDataImportsRequest", ListDataImportsRequest
)


@dataclass(eq=False, repr=False)
class ListDataImportsResponse(betterproto2.Message):
    data_imports: "list[DataImport]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )

    next_page_token: "str" = betterproto2.field(2, betterproto2.TYPE_STRING)


default_message_pool.register_message(
    "sift.data_imports.v2", "ListDataImportsResponse", ListDataImportsResponse
)


@dataclass(eq=False, repr=False)
class RetryDataImportRequest(betterproto2.Message):
    data_import_id: "str" = betterproto2.field(1, betterproto2.TYPE_STRING)
    """
    data_import_id is the id of the data import to retry.
    You can only retry an import that is a "url" based import (created with CreateDataImportFromUrl) and is in a failed state.
    """


default_message_pool.register_message(
    "sift.data_imports.v2", "RetryDataImportRequest", RetryDataImportRequest
)


@dataclass(eq=False, repr=False)
class RetryDataImportResponse(betterproto2.Message):
    pass


default_message_pool.register_message(
    "sift.data_imports.v2", "RetryDataImportResponse", RetryDataImportResponse
)


@dataclass(eq=False, repr=False)
class TdmsConfig(betterproto2.Message):
    asset_name: "str" = betterproto2.field(1, betterproto2.TYPE_STRING)

    run_name: "str" = betterproto2.field(2, betterproto2.TYPE_STRING)

    start_time_override: "datetime.datetime | None" = betterproto2.field(
        3, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Override the wf_start_time metadata field for all channels.
    Useful if your waveform channels have wf_increment but no wf_start_time (Veristand is guilty of this).
    """


default_message_pool.register_message("sift.data_imports.v2", "TDMSConfig", TdmsConfig)


class DataImportServiceStub:
    def __init__(self, channel: grpc.Channel):
        self._channel = channel

    def create_data_import_from_url(
        self, message: "CreateDataImportFromUrlRequest"
    ) -> "CreateDataImportFromUrlResponse":
        return self._channel.unary_unary(
            "/sift.data_imports.v2.DataImportService/CreateDataImportFromUrl",
            CreateDataImportFromUrlRequest.SerializeToString,
            CreateDataImportFromUrlResponse.FromString,
        )(message)

    def create_data_import_from_upload(
        self, message: "CreateDataImportFromUploadRequest"
    ) -> "CreateDataImportFromUploadResponse":
        return self._channel.unary_unary(
            "/sift.data_imports.v2.DataImportService/CreateDataImportFromUpload",
            CreateDataImportFromUploadRequest.SerializeToString,
            CreateDataImportFromUploadResponse.FromString,
        )(message)

    def detect_config(self, message: "DetectConfigRequest") -> "DetectConfigResponse":
        return self._channel.unary_unary(
            "/sift.data_imports.v2.DataImportService/DetectConfig",
            DetectConfigRequest.SerializeToString,
            DetectConfigResponse.FromString,
        )(message)

    def list_data_imports(
        self, message: "ListDataImportsRequest"
    ) -> "ListDataImportsResponse":
        return self._channel.unary_unary(
            "/sift.data_imports.v2.DataImportService/ListDataImports",
            ListDataImportsRequest.SerializeToString,
            ListDataImportsResponse.FromString,
        )(message)

    def retry_data_import(
        self, message: "RetryDataImportRequest"
    ) -> "RetryDataImportResponse":
        return self._channel.unary_unary(
            "/sift.data_imports.v2.DataImportService/RetryDataImport",
            RetryDataImportRequest.SerializeToString,
            RetryDataImportResponse.FromString,
        )(message)

    def get_data_import(
        self, message: "GetDataImportRequest"
    ) -> "GetDataImportResponse":
        return self._channel.unary_unary(
            "/sift.data_imports.v2.DataImportService/GetDataImport",
            GetDataImportRequest.SerializeToString,
            GetDataImportResponse.FromString,
        )(message)


class DataImportServiceAsyncStub(betterproto2.ServiceStub):
    async def create_data_import_from_url(
        self,
        message: "CreateDataImportFromUrlRequest",
        *,
        timeout: "float | None" = None,
        deadline: "Deadline | None" = None,
        metadata: "MetadataLike | None" = None,
    ) -> "CreateDataImportFromUrlResponse":
        return await self._unary_unary(
            "/sift.data_imports.v2.DataImportService/CreateDataImportFromUrl",
            message,
            CreateDataImportFromUrlResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def create_data_import_from_upload(
        self,
        message: "CreateDataImportFromUploadRequest",
        *,
        timeout: "float | None" = None,
        deadline: "Deadline | None" = None,
        metadata: "MetadataLike | None" = None,
    ) -> "CreateDataImportFromUploadResponse":
        return await self._unary_unary(
            "/sift.data_imports.v2.DataImportService/CreateDataImportFromUpload",
            message,
            CreateDataImportFromUploadResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def detect_config(
        self,
        message: "DetectConfigRequest",
        *,
        timeout: "float | None" = None,
        deadline: "Deadline | None" = None,
        metadata: "MetadataLike | None" = None,
    ) -> "DetectConfigResponse":
        return await self._unary_unary(
            "/sift.data_imports.v2.DataImportService/DetectConfig",
            message,
            DetectConfigResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def list_data_imports(
        self,
        message: "ListDataImportsRequest",
        *,
        timeout: "float | None" = None,
        deadline: "Deadline | None" = None,
        metadata: "MetadataLike | None" = None,
    ) -> "ListDataImportsResponse":
        return await self._unary_unary(
            "/sift.data_imports.v2.DataImportService/ListDataImports",
            message,
            ListDataImportsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def retry_data_import(
        self,
        message: "RetryDataImportRequest",
        *,
        timeout: "float | None" = None,
        deadline: "Deadline | None" = None,
        metadata: "MetadataLike | None" = None,
    ) -> "RetryDataImportResponse":
        return await self._unary_unary(
            "/sift.data_imports.v2.DataImportService/RetryDataImport",
            message,
            RetryDataImportResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )

    async def get_data_import(
        self,
        message: "GetDataImportRequest",
        *,
        timeout: "float | None" = None,
        deadline: "Deadline | None" = None,
        metadata: "MetadataLike | None" = None,
    ) -> "GetDataImportResponse":
        return await self._unary_unary(
            "/sift.data_imports.v2.DataImportService/GetDataImport",
            message,
            GetDataImportResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )


from ...common.type import v1 as __common__type__v1__


class DataImportServiceBase(ServiceBase):
    async def create_data_import_from_url(
        self, message: "CreateDataImportFromUrlRequest"
    ) -> "CreateDataImportFromUrlResponse":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def create_data_import_from_upload(
        self, message: "CreateDataImportFromUploadRequest"
    ) -> "CreateDataImportFromUploadResponse":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def detect_config(
        self, message: "DetectConfigRequest"
    ) -> "DetectConfigResponse":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def list_data_imports(
        self, message: "ListDataImportsRequest"
    ) -> "ListDataImportsResponse":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def retry_data_import(
        self, message: "RetryDataImportRequest"
    ) -> "RetryDataImportResponse":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def get_data_import(
        self, message: "GetDataImportRequest"
    ) -> "GetDataImportResponse":
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def __rpc_create_data_import_from_url(
        self,
        stream: "grpclib.server.Stream[CreateDataImportFromUrlRequest, CreateDataImportFromUrlResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_data_import_from_url(request)
        await stream.send_message(response)

    async def __rpc_create_data_import_from_upload(
        self,
        stream: "grpclib.server.Stream[CreateDataImportFromUploadRequest, CreateDataImportFromUploadResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.create_data_import_from_upload(request)
        await stream.send_message(response)

    async def __rpc_detect_config(
        self, stream: "grpclib.server.Stream[DetectConfigRequest, DetectConfigResponse]"
    ) -> None:
        request = await stream.recv_message()
        response = await self.detect_config(request)
        await stream.send_message(response)

    async def __rpc_list_data_imports(
        self,
        stream: "grpclib.server.Stream[ListDataImportsRequest, ListDataImportsResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.list_data_imports(request)
        await stream.send_message(response)

    async def __rpc_retry_data_import(
        self,
        stream: "grpclib.server.Stream[RetryDataImportRequest, RetryDataImportResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.retry_data_import(request)
        await stream.send_message(response)

    async def __rpc_get_data_import(
        self,
        stream: "grpclib.server.Stream[GetDataImportRequest, GetDataImportResponse]",
    ) -> None:
        request = await stream.recv_message()
        response = await self.get_data_import(request)
        await stream.send_message(response)

    def __mapping__(self) -> "dict[str, grpclib.const.Handler]":
        return {
            "/sift.data_imports.v2.DataImportService/CreateDataImportFromUrl": grpclib.const.Handler(
                self.__rpc_create_data_import_from_url,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateDataImportFromUrlRequest,
                CreateDataImportFromUrlResponse,
            ),
            "/sift.data_imports.v2.DataImportService/CreateDataImportFromUpload": grpclib.const.Handler(
                self.__rpc_create_data_import_from_upload,
                grpclib.const.Cardinality.UNARY_UNARY,
                CreateDataImportFromUploadRequest,
                CreateDataImportFromUploadResponse,
            ),
            "/sift.data_imports.v2.DataImportService/DetectConfig": grpclib.const.Handler(
                self.__rpc_detect_config,
                grpclib.const.Cardinality.UNARY_UNARY,
                DetectConfigRequest,
                DetectConfigResponse,
            ),
            "/sift.data_imports.v2.DataImportService/ListDataImports": grpclib.const.Handler(
                self.__rpc_list_data_imports,
                grpclib.const.Cardinality.UNARY_UNARY,
                ListDataImportsRequest,
                ListDataImportsResponse,
            ),
            "/sift.data_imports.v2.DataImportService/RetryDataImport": grpclib.const.Handler(
                self.__rpc_retry_data_import,
                grpclib.const.Cardinality.UNARY_UNARY,
                RetryDataImportRequest,
                RetryDataImportResponse,
            ),
            "/sift.data_imports.v2.DataImportService/GetDataImport": grpclib.const.Handler(
                self.__rpc_get_data_import,
                grpclib.const.Cardinality.UNARY_UNARY,
                GetDataImportRequest,
                GetDataImportResponse,
            ),
        }
