{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b202351",
   "metadata": {},
   "source": [
    "# Sift Client Ingestion Examples\n",
    "\n",
    "This notebook demonstrates features of SiftClient ingestion, from basic usage to advanced patterns.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "**Important**: The ingestion streaming client requires the `sift-stream` optional dependency. Install it with:\n",
    "\n",
    "```bash\n",
    "pip install sift-stack-py[sift-stream]\n",
    "```\n",
    "\n",
    "## Topics Covered\n",
    "\n",
    "1. **Basic Example**: Simple single flow sending\n",
    "2. **Batch Sending**: Efficiently sending multiple flows at once\n",
    "3. **Advanced Concepts**: Recovery strategies, checkpoints, and more\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b324ed85",
   "metadata": {},
   "source": [
    "## 1. Basic Example: Sending Individual Flows\n",
    "\n",
    "This example shows the simplest way to send telemetry data to Sift:\n",
    "- Create an ingestion config with flow definitions\n",
    "- Create a run to associate data with\n",
    "- Send individual flows one at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b75dbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "from sift_client import SiftClient, SiftConnectionConfig\n",
    "from sift_client.sift_types import (\n",
    "    ChannelConfig,\n",
    "    ChannelDataType,\n",
    "    FlowConfig,\n",
    "    IngestionConfigCreate,\n",
    "    RunCreate,\n",
    ")\n",
    "\n",
    "\n",
    "async def basic_example():\n",
    "    # Configure connection to Sift\n",
    "    connection_config = SiftConnectionConfig(\n",
    "        api_key=\"my_api_key\",\n",
    "        grpc_url=\"sift_grpc_url\",\n",
    "        rest_url=\"sift_rest_url\",\n",
    "    )\n",
    "\n",
    "    client = SiftClient(connection_config=connection_config)\n",
    "\n",
    "    # Define your telemetry schema using an ingestion config\n",
    "    ingestion_config = IngestionConfigCreate(\n",
    "        asset_name=\"sift_rover_1\",\n",
    "        flows=[\n",
    "            FlowConfig(\n",
    "                name=\"onboard_sensors\",\n",
    "                channels=[\n",
    "                    ChannelConfig(\n",
    "                        name=\"motor_temp\",\n",
    "                        unit=\"C\",\n",
    "                        data_type=ChannelDataType.DOUBLE\n",
    "                    ),\n",
    "                    ChannelConfig(\n",
    "                        name=\"tank_pressure\",\n",
    "                        unit=\"kPa\",\n",
    "                        data_type=ChannelDataType.DOUBLE\n",
    "                    ),\n",
    "                ],\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Create a run to associate this data collection session\n",
    "    run = RunCreate(name=\"sift_rover-\" + str(int(time.time())))\n",
    "\n",
    "    # Create the streaming client\n",
    "    async with await client.async_.ingestion.create_ingestion_config_streaming_client(\n",
    "        ingestion_config=ingestion_config,\n",
    "        run=run,\n",
    "    ) as ingest_client:\n",
    "        # Send data in a loop\n",
    "        for i in range(10):\n",
    "            # Get the flow config to create flows\n",
    "            flow_config = ingest_client.get_flow_config(flow_name=\"onboard_sensors\")\n",
    "\n",
    "            # Create a flow with timestamp and values\n",
    "            # The timestamp can also be left out to default to datetime.now(timezone.utc)\n",
    "            flow = flow_config.as_flow(\n",
    "                timestamp=datetime.now(timezone.utc),\n",
    "                values={\n",
    "                    \"motor_temp\": 50.0 + random.random() * 5.0,\n",
    "                    \"tank_pressure\": 2000.0 + random.random() * 100.0,\n",
    "                },\n",
    "            )\n",
    "\n",
    "            # Send the flow to Sift\n",
    "            await ingest_client.send(flow=flow)\n",
    "\n",
    "            await asyncio.sleep(0.1)\n",
    "\n",
    "\n",
    "# Uncomment to run:\n",
    "# asyncio.run(basic_example())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bf10f3",
   "metadata": {},
   "source": [
    "## 2. Batch Sending: Efficiently Sending Multiple Flows\n",
    "\n",
    "For potentially better performance when sending many flows, use `batch_send()` to send multiple flows in a single operation. This may reduce the overhead of calling the underlying Rust SiftStream ingestion client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aec10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def batch_send_example():\n",
    "    \"\"\"Example showing how to efficiently send multiple flows at once.\"\"\"\n",
    "    connection_config = SiftConnectionConfig(\n",
    "        api_key=\"my_api_key\",\n",
    "        grpc_url=\"sift_grpc_url\",\n",
    "        rest_url=\"sift_rest_url\",\n",
    "    )\n",
    "\n",
    "    client = SiftClient(connection_config=connection_config)\n",
    "\n",
    "    ingestion_config = IngestionConfigCreate(\n",
    "        asset_name=\"sift_rover_1\",\n",
    "        flows=[\n",
    "            FlowConfig(\n",
    "                name=\"onboard_sensors\",\n",
    "                channels=[\n",
    "                    ChannelConfig(\n",
    "                        name=\"motor_temp\",\n",
    "                        unit=\"C\",\n",
    "                        data_type=ChannelDataType.DOUBLE\n",
    "                    ),\n",
    "                    ChannelConfig(\n",
    "                        name=\"tank_pressure\",\n",
    "                        unit=\"kPa\",\n",
    "                        data_type=ChannelDataType.DOUBLE\n",
    "                    ),\n",
    "                ],\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    run = RunCreate(name=\"sift_rover-\" + str(int(time.time())))\n",
    "\n",
    "    async with await client.async_.ingestion.create_ingestion_config_streaming_client(\n",
    "        ingestion_config=ingestion_config,\n",
    "        run=run,\n",
    "    ) as ingest_client:\n",
    "        flow_config = ingest_client.get_flow_config(flow_name=\"onboard_sensors\")\n",
    "\n",
    "        # Generate 5 seconds of data at 10Hz (10 flows per second = 50 flows total)\n",
    "        sample_rate_hz = 10\n",
    "        duration_seconds = 5\n",
    "        num_flows = sample_rate_hz * duration_seconds  # 50 flows\n",
    "\n",
    "        start_time = datetime.now(timezone.utc)\n",
    "        flows = []\n",
    "        for i in range(num_flows):\n",
    "            # Calculate timestamp for each sample (spaced 0.1 seconds apart)\n",
    "            timestamp = start_time + timedelta(seconds=i / sample_rate_hz)\n",
    "            flows.append(\n",
    "                flow_config.as_flow(\n",
    "                    timestamp=timestamp,\n",
    "                    values={\n",
    "                        \"motor_temp\": 50.0 + random.random() * 5.0,\n",
    "                        \"tank_pressure\": 2000.0 + random.random() * 100.0,\n",
    "                    },\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Send all flows in a single batch operation\n",
    "        # batch_send supports sending any iterables of Flow or FlowPy objects\n",
    "        await ingest_client.batch_send(flows)\n",
    "\n",
    "\n",
    "# Uncomment to run:\n",
    "# asyncio.run(batch_send_example())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab425ee7",
   "metadata": {},
   "source": [
    "## 3. Advanced Concepts\n",
    "\n",
    "### Recovery Strategies\n",
    "\n",
    "Recovery strategies can be used to allow fine-tuned control of SiftStream ingestion:\n",
    "- **Retry with Backups [DEFAULT]**: Retry failed connections + temporarily keep backups of ingested data for automatic re-ingestion if a streaming checkpoint (defaults to 60s) fails to send all data.\n",
    "- **Retry Only**: Retry failed connections only. More performant, but with no guarantee of data ingestion in the event of a connection issue.\n",
    "\n",
    "### Tracing\n",
    "\n",
    "Tracing allows you to monitor and debug SiftStream ingestion through logs. You can configure tracing in several ways:\n",
    "\n",
    "- **Console Only**: Output logs to stdout/stderr only\n",
    "- **File Logging**: Output logs to both console and rolling log files\n",
    "- **Disabled**: Turn off tracing entirely\n",
    "\n",
    "Tracing is initialized once per process, and cannot be modified afterward.\n",
    "\n",
    "### Metrics\n",
    "\n",
    "SiftStream provides detailed metrics about ingestion performance. Use `get_metrics_snapshot()` to access:\n",
    "\n",
    "- **Bytes sent**: Total bytes successfully sent to Sift\n",
    "- **Byte rate**: Current throughput in bytes per second\n",
    "- **Messages sent**: Total number of flows/messages sent\n",
    "- **Message rate**: Current message throughput\n",
    "- **Checkpoint metrics**: Timing and counts for checkpoints\n",
    "- **Backup metrics**: Statistics about disk backups (if enabled)\n",
    "\n",
    "Metrics are updated in real-time and can help you monitor ingestion health and performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc45400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sift_client.resources.ingestion import RecoveryStrategyConfig, TracingConfig\n",
    "\n",
    "\n",
    "async def advanced_example():\n",
    "    \"\"\"Example with recovery strategies, tracing, and metrics.\"\"\"\n",
    "    connection_config = SiftConnectionConfig(\n",
    "        api_key=\"my_api_key\",\n",
    "        grpc_url=\"sift_grpc_url\",\n",
    "        rest_url=\"sift_rest_url\",\n",
    "    )\n",
    "\n",
    "    client = SiftClient(connection_config=connection_config)\n",
    "\n",
    "    ingestion_config = IngestionConfigCreate(\n",
    "        asset_name=\"sift_rover_1\",\n",
    "        flows=[\n",
    "            FlowConfig(\n",
    "                name=\"onboard_sensors\",\n",
    "                channels=[\n",
    "                    ChannelConfig(\n",
    "                        name=\"motor_temp\",\n",
    "                        unit=\"C\",\n",
    "                        data_type=ChannelDataType.DOUBLE\n",
    "                    ),\n",
    "                    ChannelConfig(\n",
    "                        name=\"tank_pressure\",\n",
    "                        unit=\"kPa\",\n",
    "                        data_type=ChannelDataType.DOUBLE\n",
    "                    ),\n",
    "                ],\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    run = RunCreate(name=\"sift_rover-\" + str(int(time.time())))\n",
    "\n",
    "    # Use retry only for better performance (no backups)\n",
    "    recovery_strategy = RecoveryStrategyConfig.retry_only()\n",
    "\n",
    "    # Use console-only tracing (stdout/stderr) instead of file logging\n",
    "    tracing_config = TracingConfig.console_only(level=\"info\")\n",
    "\n",
    "    async with await client.async_.ingestion.create_ingestion_config_streaming_client(\n",
    "        ingestion_config=ingestion_config,\n",
    "        run=run,\n",
    "        recovery_strategy=recovery_strategy,\n",
    "        tracing_config=tracing_config,\n",
    "    ) as ingest_client:\n",
    "        flow_config = ingest_client.get_flow_config(flow_name=\"onboard_sensors\")\n",
    "\n",
    "        # Send some flows\n",
    "        for i in range(10):\n",
    "            flow = flow_config.as_flow(\n",
    "                timestamp=datetime.now(timezone.utc),\n",
    "                values={\n",
    "                    \"motor_temp\": 50.0 + random.random() * 5.0,\n",
    "                    \"tank_pressure\": 2000.0 + random.random() * 100.0,\n",
    "                },\n",
    "            )\n",
    "            await ingest_client.send(flow=flow)\n",
    "\n",
    "        # Get metrics snapshot to see ingestion statistics\n",
    "        metrics = ingest_client.get_metrics_snapshot()\n",
    "        print(\"\\n=== Ingestion Metrics ===\")\n",
    "        print(f\"Bytes sent: {metrics.bytes_sent:,}\")\n",
    "        print(f\"Byte rate: {metrics.byte_rate:,} bytes/s\")\n",
    "        print(f\"Messages sent: {metrics.messages_sent:,}\")\n",
    "        print(f\"Message rate: {metrics.message_rate:.2f} messages/s\")\n",
    "\n",
    "        # Additional metrics available:\n",
    "        # - metrics.checkpoint_metrics: Checkpoint timing and counts\n",
    "        # - metrics.backup_metrics: Backup statistics (if backups enabled)\n",
    "\n",
    "\n",
    "# Uncomment to run:\n",
    "# asyncio.run(advanced_example())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
